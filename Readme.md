# Enterprise-RAG-QA

Enterprise-RAG-QA is a production-ready Question-Answering system built using **Retrieval-Augmented Generation (RAG)**.  
It retrieves relevant information from enterprise documents (PDFs, reports, knowledge bases, etc.) and generates accurate answers using Large Language Models (LLMs).

This project follows real-world engineering standards:

- Modular RAG pipeline
- REST API using FastAPI
- Evaluation metrics framework
- Test suite with coverage
- CI regression protection
- Docker compatible

---

## ðŸ“‚ Project Structure

```bash
enterprise-rag-qa/
â”‚
â”œâ”€â”€ app/                     # FastAPI application
â”‚   â””â”€â”€ main.py
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ evaluation/          # Evaluation + metrics
â”‚   â”œâ”€â”€ generation/          # RAG pipeline + LLM orchestration
â”‚   â”œâ”€â”€ ingestion/           # Chunking + embedding + indexing
â”‚   â”œâ”€â”€ retrieval/           # Vector search components
â”‚   â”œâ”€â”€ utils/               # Helper utilities
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ tests/                   # Unit + API tests
â”œâ”€â”€ scripts/                 # Metric validation scripts
â”œâ”€â”€ data/                    # Input document storage
â”œâ”€â”€ vector_db/               # FAISS index files
â”œâ”€â”€ .github/workflows/       # CI configuration
â”œâ”€â”€ Dockerfile               # Build container image
â”œâ”€â”€ requirements.txt         # Dependencies
â””â”€â”€ README.md
```

## Features

â€¢ Retrieval-Augmented Generation (RAG) pipeline
â€¢ Chunk-based document ingestion
â€¢ Dense vector similarity search using FAISS
â€¢ LLM-powered answer synthesis
â€¢ Confidence scoring support
â€¢ Offline evaluation suite
â€¢ CI-protected quality gates
